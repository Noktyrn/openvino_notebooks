{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POT Simplified Mode tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "from compression.api import DataLoader\n",
    "from addict import Dict\n",
    "\n",
    "# Set the data and model directories\n",
    "MODEL_DIR = 'model'\n",
    "CALIB_DIR = 'calib'\n",
    "CIFAR_DIR = 'cifar'\n",
    "CALIB_SET_SIZE = 300\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(CALIB_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create the calibration dataset from the preprocessed ImageNet images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "transform = T.Compose([T.ToTensor()])\n",
    "dataset = CIFAR10(root=CIFAR_DIR, train=False, transform=transform, download=True)\n",
    "class CifarDataLoader(DataLoader):\n",
    "\n",
    "    def __init__(self, config, dataset, shuffle=True):\n",
    "        \"\"\"\n",
    "        Initialize config and dataset.\n",
    "        :param config: created config with DATA_DIR path.\n",
    "        \"\"\"\n",
    "        if not isinstance(config, Dict):\n",
    "            config = Dict(config)\n",
    "        super().__init__(config)\n",
    "        self.data = self.load_data(dataset, shuffle)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Return one sample of index, label and picture.\n",
    "        :param index: index of the taken sample.\n",
    "        \"\"\"\n",
    "        if index >= len(self):\n",
    "            raise IndexError\n",
    "\n",
    "        return (self.data[index][0], self.data[index][2]), self.data[index][1].squeeze(0)\n",
    "\n",
    "    def load_data(self, dataset, shuffle):\n",
    "        \"\"\"\n",
    "        Load dataset in needed format. \n",
    "        :param dataset:  downloaded dataset.\n",
    "        \"\"\"\n",
    "        data = [(idx, sample[0], sample[1]) for idx, sample in enumerate(dataset)]\n",
    "        if shuffle:\n",
    "            random.shuffle(data)\n",
    "        return data\n",
    "\n",
    "dataset_config = Dict({\n",
    "    'data_source': CIFAR_DIR\n",
    "})\n",
    "data_loader = CifarDataLoader(dataset_config, dataset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_converter = T.ToPILImage(mode=\"RGB\")\n",
    "counter = 0\n",
    "for info, im in data_loader:\n",
    "    idx = info[0]\n",
    "    if counter >= CALIB_SET_SIZE:\n",
    "        break\n",
    "    label = info[1]\n",
    "    pil_converter(im).save(Path(CALIB_DIR) / f'{label}_{idx}.png')\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first step we need to export the model, which we need to optimize, into the ONNX format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/tagir/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg19_bn\", pretrained=True)\n",
    "dummy_input = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "onnx_model_path = Path(MODEL_DIR) / 'vgg19.onnx'\n",
    "ir_model_xml = onnx_model_path.with_suffix('.xml')\n",
    "ir_model_bin = onnx_model_path.with_suffix('.bin')\n",
    "\n",
    "torch.onnx.export(model, dummy_input, onnx_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert this model into the OpenVINO IR using the Model Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/tagir/work/openvino_notebooks/notebooks/114-simplified-mode/model/vgg19.onnx\n",
      "\t- Path for generated IR: \t/home/tagir/work/openvino_notebooks/notebooks/114-simplified-mode/model\n",
      "\t- IR output name: \tvgg19\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \t[1,3,32,32]\n",
      "\t- Source layout: \tNot specified\n",
      "\t- Target layout: \tNot specified\n",
      "\t- Layout: \tNot specified\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tNone\n",
      "\t- Reverse input channels: \tFalse\n",
      "\t- Use legacy API for model processing: \tFalse\n",
      "\t- Use the transformations config file: \tNone\n",
      "\t- OpenVINO runtime found in: \t/home/tagir/work/openvino_notebooks/env/lib/python3.7/site-packages/openvino\n",
      "OpenVINO runtime version: \t2022.1.0-6582-50dffb80bb9\n",
      "Model Optimizer version: \t2022.1.0-6386-d5b74b0c6b3\n",
      "[ WARNING ] Model Optimizer and OpenVINO runtime versions do no match.\n",
      "[ WARNING ] Consider building the OpenVINO Python API from sources or reinstall OpenVINO (TM) toolkit using \"pip install openvino==2022.1\"\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /home/tagir/work/openvino_notebooks/notebooks/114-simplified-mode/model/vgg19.xml\n",
      "[ SUCCESS ] BIN file: /home/tagir/work/openvino_notebooks/notebooks/114-simplified-mode/model/vgg19.bin\n",
      "[ SUCCESS ] Total execution time: 0.73 seconds. \n",
      "[ SUCCESS ] Memory consumed: 233 MB. \n",
      "It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*\n"
     ]
    }
   ],
   "source": [
    "!mo --framework=onnx --data_type=FP16 --input_shape=[1,3,32,32] -m $onnx_model_path  --output_dir $MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we need to write the optimization config and export it to .json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict({\n",
    "    \"model\": {\n",
    "        \"model_name\": \"vgg19\",\n",
    "        \"model\": str(ir_model_xml),\n",
    "        \"weights\": str(ir_model_bin)\n",
    "    },\n",
    "\n",
    "    \"engine\": {\n",
    "        \"type\": \"simplified\",\n",
    "        \"data_source\": CALIB_DIR\n",
    "    },\n",
    "\n",
    "    \"compression\": {\n",
    "        \"target_device\": \"ANY\",\n",
    "        \"algorithms\": [\n",
    "            {\n",
    "                \"name\": \"DefaultQuantization\",\n",
    "                \"params\": {\n",
    "                    \"preset\": \"performance\",\n",
    "                    \"stat_subset_size\": 300\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "})\n",
    "\n",
    "with open(\"config.json\", \"w\") as outfile:\n",
    "    json.dump(config, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can optimize the model using this configuration file by calling the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:openvino.tools.pot.app.run:Output log dir: compressed/vgg19_DefaultQuantization/2022-02-16_14-38-44\n",
      "INFO:openvino.tools.pot.app.run:Creating pipeline:\n",
      " Algorithm: DefaultQuantization\n",
      " Parameters:\n",
      "\tpreset                     : performance\n",
      "\tstat_subset_size           : 300\n",
      "\ttarget_device              : ANY\n",
      "\tmodel_type                 : None\n",
      "\tdump_intermediate_model    : False\n",
      "\tinplace_statistics         : True\n",
      "\texec_log_dir               : compressed/vgg19_DefaultQuantization/2022-02-16_14-38-44\n",
      " ===========================================================================\n",
      "INFO:openvino.tools.pot.pipeline.pipeline:Inference Engine version:                2022.1.0-6582-50dffb80bb9\n",
      "INFO:openvino.tools.pot.pipeline.pipeline:Model Optimizer version:                 2022.1.0-6386-d5b74b0c6b3\n",
      "INFO:openvino.tools.pot.pipeline.pipeline:Post-Training Optimization Tool version: 2022.1.0-6386-d5b74b0c6b3\n",
      "INFO:openvino.tools.pot.statistics.collector:Start computing statistics for algorithms : DefaultQuantization\n",
      "INFO:openvino.tools.pot.statistics.collector:Computing statistics finished\n",
      "INFO:openvino.tools.pot.pipeline.pipeline:Start algorithm: DefaultQuantization\n",
      "INFO:openvino.tools.pot.algorithms.quantization.default.algorithm:Start computing statistics for algorithm : ActivationChannelAlignment\n",
      "INFO:openvino.tools.pot.algorithms.quantization.default.algorithm:Computing statistics finished\n",
      "INFO:openvino.tools.pot.algorithms.quantization.default.algorithm:Start computing statistics for algorithms : MinMaxQuantization,FastBiasCorrection\n",
      "INFO:openvino.tools.pot.algorithms.quantization.default.algorithm:Computing statistics finished\n",
      "INFO:openvino.tools.pot.pipeline.pipeline:Finished: DefaultQuantization\n",
      " ===========================================================================\n"
     ]
    }
   ],
   "source": [
    "!pot --output-dir compressed -c config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you need to set the new optimized model path.\n",
    "\n",
    "It looks like \"compressed/{MODEL_NAME}_DefaultQuantization/{DateTime}/optimized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_model_path = Path('compressed/vgg19_DefaultQuantization/2022-02-16_14-38-44/optimized')\n",
    "optimized_model_xml = optimized_model_path / 'vgg19.xml'\n",
    "optimized_model_bin = optimized_model_path / 'vgg19.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ WARNING ]  -nstreams default value is determined automatically for a device. Although the automatic selection usually provides a reasonable performance, but it still may be non-optimal for some cases, for more information look at README. \n",
      "[Step 2/11] Loading OpenVINO\n",
      "[ WARNING ] -hint default value is determined as 'THROUGHPUT' automatically for CPU deviceFor more detailed information look at README.\n",
      "[ INFO ] OpenVINO:\n",
      "         API version............. 2022.1.0-6582-50dffb80bb9\n",
      "[ INFO ] Device info\n",
      "         CPU\n",
      "         openvino_intel_cpu_plugin version 2022.1\n",
      "         Build................... 2022.1.0-6582-50dffb80bb9\n",
      "\n",
      "[Step 3/11] Setting device configuration\n",
      "[ WARNING ] -nstreams default value is determined automatically for CPU device. Although the automatic selection usually provides a reasonable performance, but it still may be non-optimal for some cases, for more information look at README.\n",
      "[Step 4/11] Reading network files\n",
      "[ INFO ] Read model took 20.14 ms\n",
      "[Step 5/11] Resizing network to match image sizes and given batch\n",
      "[ INFO ] Network batch size: 1\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model input 'input.1' precision u8, dimensions ([N,C,H,W]): 1 3 32 32\n",
      "[ INFO ] Model output '177' precision f32, dimensions ([...]): 1 10\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 142.34 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] DEVICE: CPU\n",
      "[ INFO ]   CACHE_DIR  , \n",
      "[ INFO ]   CPU_BIND_THREAD  , YES\n",
      "[ INFO ]   CPU_THREADS_NUM  , 0\n",
      "[ INFO ]   CPU_THROUGHPUT_STREAMS  , 6\n",
      "[ INFO ]   DUMP_EXEC_GRAPH_AS_DOT  , \n",
      "[ INFO ]   DYN_BATCH_ENABLED  , NO\n",
      "[ INFO ]   DYN_BATCH_LIMIT  , 0\n",
      "[ INFO ]   ENFORCE_BF16  , NO\n",
      "[ INFO ]   EXCLUSIVE_ASYNC_REQUESTS  , NO\n",
      "[ INFO ]   PERFORMANCE_HINT  , THROUGHPUT\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS  , 0\n",
      "[ INFO ]   PERF_COUNT  , NO\n",
      "[Step 9/11] Creating infer requests and preparing input data\n",
      "[ INFO ] Create 6 infer requests took 1.07 ms\n",
      "[ WARNING ] No input files were given for input 'input.1'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'input.1' with random values \n",
      "[ INFO ] Benchmarking in inference only mode (inputs filling are not included in measurement loop).\n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 6 inference requests using 6 streams for CPU, inference only: True, limits: 60000 ms duration)\n",
      "[ INFO ] First inference took 8.77 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "Count:          76422 iterations\n",
      "Duration:       60006.00 ms\n",
      "Latency:\n",
      "    Median:     4.57 ms\n",
      "    AVG:        4.61 ms\n",
      "    MIN:        3.42 ms\n",
      "    MAX:        12.47 ms\n",
      "Throughput: 1273.57 FPS\n"
     ]
    }
   ],
   "source": [
    "# Inference FP32 model (IR)\n",
    "!benchmark_app -m $ir_model_xml -d CPU -api async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ WARNING ]  -nstreams default value is determined automatically for a device. Although the automatic selection usually provides a reasonable performance, but it still may be non-optimal for some cases, for more information look at README. \n",
      "[Step 2/11] Loading OpenVINO\n",
      "[ WARNING ] -hint default value is determined as 'THROUGHPUT' automatically for CPU deviceFor more detailed information look at README.\n",
      "[ INFO ] OpenVINO:\n",
      "         API version............. 2022.1.0-6582-50dffb80bb9\n",
      "[ INFO ] Device info\n",
      "         CPU\n",
      "         openvino_intel_cpu_plugin version 2022.1\n",
      "         Build................... 2022.1.0-6582-50dffb80bb9\n",
      "\n",
      "[Step 3/11] Setting device configuration\n",
      "[ WARNING ] -nstreams default value is determined automatically for CPU device. Although the automatic selection usually provides a reasonable performance, but it still may be non-optimal for some cases, for more information look at README.\n",
      "[Step 4/11] Reading network files\n",
      "[ INFO ] Read model took 13.91 ms\n",
      "[Step 5/11] Resizing network to match image sizes and given batch\n",
      "[ INFO ] Network batch size: 1\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model input 'input.1' precision u8, dimensions ([N,C,H,W]): 1 3 32 32\n",
      "[ INFO ] Model output '177' precision f32, dimensions ([...]): 1 10\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 70.69 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] DEVICE: CPU\n",
      "[ INFO ]   CACHE_DIR  , \n",
      "[ INFO ]   CPU_BIND_THREAD  , YES\n",
      "[ INFO ]   CPU_THREADS_NUM  , 0\n",
      "[ INFO ]   CPU_THROUGHPUT_STREAMS  , 6\n",
      "[ INFO ]   DUMP_EXEC_GRAPH_AS_DOT  , \n",
      "[ INFO ]   DYN_BATCH_ENABLED  , NO\n",
      "[ INFO ]   DYN_BATCH_LIMIT  , 0\n",
      "[ INFO ]   ENFORCE_BF16  , NO\n",
      "[ INFO ]   EXCLUSIVE_ASYNC_REQUESTS  , NO\n",
      "[ INFO ]   PERFORMANCE_HINT  , THROUGHPUT\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS  , 0\n",
      "[ INFO ]   PERF_COUNT  , NO\n",
      "[Step 9/11] Creating infer requests and preparing input data\n",
      "[ INFO ] Create 6 infer requests took 1.51 ms\n",
      "[ WARNING ] No input files were given for input 'input.1'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'input.1' with random values \n",
      "[ INFO ] Benchmarking in inference only mode (inputs filling are not included in measurement loop).\n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 6 inference requests using 6 streams for CPU, inference only: True, limits: 60000 ms duration)\n",
      "[ INFO ] First inference took 1.85 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "Count:          287058 iterations\n",
      "Duration:       60001.98 ms\n",
      "Latency:\n",
      "    Median:     1.16 ms\n",
      "    AVG:        1.17 ms\n",
      "    MIN:        0.79 ms\n",
      "    MAX:        14.80 ms\n",
      "Throughput: 4784.14 FPS\n"
     ]
    }
   ],
   "source": [
    "# Inference INT8 model (IR)\n",
    "!benchmark_app -m $optimized_model_xml -d CPU -api async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.inference_engine import IECore\n",
    "\n",
    "ie = IECore()\n",
    "\n",
    "# read and load quantized model\n",
    "quantized_net = ie.read_network(\n",
    "    model=optimized_model_xml, weights=optimized_model_bin\n",
    ")\n",
    "quantized_net = ie.load_network(network=quantized_net, device_name=\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all possible labels from CIFAR10\n",
    "labels_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "all_pictures = []\n",
    "all_labels = []\n",
    "\n",
    "# get all pictures and their labels \n",
    "for i, batch in enumerate(data_loader):\n",
    "    all_pictures.append(batch[1])\n",
    "    all_labels.append(batch[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_pictures(indexes: list, all_pictures=all_pictures, all_labels=all_labels):\n",
    "    \"\"\"Plot 4 pictures.\n",
    "    :param indexes: a list of indexes of pictures to be displayed.\n",
    "    :param all_batches: batches with pictures.\n",
    "    \"\"\"\n",
    "    num_pics = len(indexes)\n",
    "    f, axarr = plt.subplots(1, num_pics)\n",
    "    for idx, im_idx in enumerate(indexes):\n",
    "        assert idx < 10000, 'Cannot get such index, there are only 10000'\n",
    "        pic = np.rollaxis(all_pictures[im_idx].squeeze().numpy(), 0, 3)\n",
    "        axarr[idx].imshow(pic)\n",
    "        axarr[idx].set_title(labels_names[all_labels[im_idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_on_pictures(net, indexes: list, all_pictures=all_pictures):\n",
    "    \"\"\" Inference model on a few pictures.\n",
    "    :param net: model on which do inference\n",
    "    :param indexes: list of indexes \n",
    "    \"\"\"\n",
    "    predicted_labels = []\n",
    "    for idx in indexes:\n",
    "        assert idx < 10000, 'Cannot get such index, there are only 10000'\n",
    "        result = list(net.infer(inputs={'input.1': all_pictures[idx]}).values())\n",
    "        result = labels_names[np.argmax(result[0])]\n",
    "        predicted_labels.append(result)\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels for picture from quantized model : ['cat', 'bird', 'bird'].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "indexes_to_infer = [0, 1, 2]  # to plot specify 4 indexes\n",
    "\n",
    "plot_pictures(indexes_to_infer)\n",
    "\n",
    "results_quanized = infer_on_pictures(quantized_net, indexes_to_infer)\n",
    "\n",
    "print(f\"Labels for picture from quantized model : {results_quanized}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "K5HPrY_d-7cV",
    "E01dMaR2_AFL",
    "qMnYsGo9_MA8",
    "L0tH9KdwtHhV"
   ],
   "name": "NNCF Quantization PyTorch Demo (tiny-imagenet/resnet-50)",
   "provenance": []
  },
  "interpreter": {
   "hash": "852430a53033d44ce17eefa3d9017e4bc4dca84b51e1c38a8c71aec2fd2e4d43"
  },
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
